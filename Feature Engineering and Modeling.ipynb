{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", parse_dates=['Dates'])\n",
    "test = pd.read_csv(\"data/test.csv\", parse_dates=['Dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse \"Dates\" into year, month, day, and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    data['Day'] = data['Dates'].dt.day\n",
    "    data['Month'] = data['Dates'].dt.month\n",
    "    data['Year'] = data['Dates'].dt.year\n",
    "    data['Hour'] = data['Dates'].dt.hour\n",
    "    data['Minute'] = data['Dates'].dt.minute\n",
    "    data['DayOfWeek'] = data['Dates'].dt.dayofweek\n",
    "    data['WeekOfYear'] = data['Dates'].dt.weekofyear\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = feature_engineering(train)\n",
    "X_test = feature_engineering(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['Descript','Resolution', 'Address', 'Category', 'Dates'], axis=1)\n",
    "Y_train = train['Category']\n",
    "\n",
    "X_test = X_test.drop(['Address', 'Dates'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several address don't have the correct latitude and longitude, need to impute them based on address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert categorical variables into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(X_train['PdDistrict'])\n",
    "X_train = X_train.drop('PdDistrict', axis=1)\n",
    "X_train = X_train.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(X_train['DayOfWeek'])\n",
    "X_train = X_train.drop('DayOfWeek', axis=1)\n",
    "X_train = X_train.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(X_test['PdDistrict'])\n",
    "X_test = X_test.drop('PdDistrict', axis=1)\n",
    "X_test = X_test.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(X_test['DayOfWeek'])\n",
    "X_test = X_test.drop('DayOfWeek', axis=1)\n",
    "X_test = X_test.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or 2. Encode predictors ( Either create dummy variables or encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "X_train['PdDistrict'] = enc.fit_transform(X_train['PdDistrict'])\n",
    "X_test['PdDistrict'] = enc.fit_transform(X_test['PdDistrict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "\n",
    "#to convert back\n",
    "# y_train = le.inverse_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees or Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etr = ExtraTreesClassifier(n_jobs=25, n_estimators = 100)\n",
    "etr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851773648168\n"
     ]
    }
   ],
   "source": [
    "print etr.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10215656  0.06978545]\n",
      "0.0859710075596\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(etr, X_train, Y_train, n_jobs=25, cv=5, scoring=\"accuracy\")\n",
    "print score\n",
    "print np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['predictions'] = etr.predict(X_test.ix[:,1:])\n",
    "X_test['Category'] = le.inverse_transform(X_test['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=25, n_estimators = 100)\n",
    "rf.fit(X_train, Y_train)\n",
    "print rf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = cross_val_score(rf, X_train, Y_train, n_jobs=25, cv=2, scoring=\"accuracy\")\n",
    "print score\n",
    "print np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['predictions'] = rf.predict(X_test.ix[:,1:])\n",
    "X_test['Category'] = le.inverse_transform(X_test['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output predictions to a csv file that's formatted as required by Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def field_to_columns(data, field, new_columns):\n",
    "    for i in range(len(new_columns)):\n",
    "        data[new_columns[i]] = (data[field] == new_columns[i]).astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = list(le.classes_)\n",
    "X_test = field_to_columns(X_test, 'Category', categories)\n",
    "\n",
    "# use list(X_test.columns[13:]) if you use encoding instead of creating dummies.\n",
    "submission_cols = [X_test.columns[0]] + list(X_test.columns[22:])\n",
    "X_test[submission_cols].to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
